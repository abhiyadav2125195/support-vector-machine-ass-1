{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8e7756-30dc-43d9-8227-c1cd7d768890",
   "metadata": {},
   "source": [
    "# Q1. What is the mathematical formula for a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c70663-79ed-44e6-aa0a-9cf8bfa8a77d",
   "metadata": {},
   "source": [
    "f(x) = w · x + b\n",
    "Here,\n",
    "\n",
    "f(x) represents the decision function that predicts the class label for a given input vector x.\n",
    "w is the weight vector that determines the orientation of the hyperplane.\n",
    "· denotes the dot product between w and x.\n",
    "b is the bias term that shifts the hyperplane away from the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534a28a-1ff1-4ea4-bc98-7b049c6baee9",
   "metadata": {},
   "source": [
    "# Q2. What is the objective function of a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb08e3-af95-4b6b-901f-b982a66f60d6",
   "metadata": {},
   "source": [
    "Minimize: 1/2 ||w||^2  subject to: y_i(w · x_i + b) >= 1 for all training samples (x_i, y_i)\n",
    "Here,\n",
    "\n",
    "||w||^2 represents the L2 norm of the weight vector w.\n",
    "(x_i, y_i) are the training samples where x_i is the input feature vector, and y_i is the class label (+1 or -1).\n",
    "The objective is to find the optimal w and b that maximize the margin while ensuring that all training samples are correctly classified or have a margin of at least 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f5d2-7024-437c-b749-84eebea2f5ae",
   "metadata": {},
   "source": [
    "# Q3. What is the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bcbe1-3acd-49ad-8b46-a3a3d6cb46ad",
   "metadata": {},
   "source": [
    "The kernel trick in SVM is a technique that allows SVMs to handle non-linearly separable data by implicitly mapping the input features into a higher-dimensional space where the data becomes linearly separable. Instead of computing the dot product between the original input vectors, the kernel function calculates the dot product in this higher-dimensional space without explicitly transforming the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5aa02-dad5-4fa2-8a07-3ece84fcafd7",
   "metadata": {},
   "source": [
    "# Q4. What is the role of support vectors in SVM Explain with example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f75df-5582-43b2-bd26-8b30354838eb",
   "metadata": {},
   "source": [
    "Support vectors are the data points from the training dataset that lie closest to the decision boundary (hyperplane) and have the smallest margin. They play a crucial role in SVM because they determine the position and orientation of the hyperplane. These support vectors are the only data points that influence the location of the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d37d3-b120-48b9-bc43-4ded50b2c1d5",
   "metadata": {},
   "source": [
    "# Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cafc123-8af9-4cff-8142-05024151dd66",
   "metadata": {},
   "source": [
    "Hyperplane: The hyperplane is the decision boundary that separates two classes in a binary classification problem.\n",
    "\n",
    "Marginal Plane: The marginal plane is a pair of parallel planes that are equidistant from the hyperplane. These planes define the margin, and support vectors lie on or between them.\n",
    "\n",
    "Hard Margin: In a hard margin SVM, the goal is to find a hyperplane that completely separates the two classes without any misclassifications. This is suitable for linearly separable data.\n",
    "\n",
    "Soft Margin: In a soft margin SVM, the goal is to find a hyperplane that allows for some misclassifications (penalized by a parameter C) to handle partially separable data or noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfdbe9-41a6-454d-9750-7489f4cfae6d",
   "metadata": {},
   "source": [
    "# Q6. SVM Implementation through Iris dataset.\n",
    "# ~ Load the iris dataset from the scikit-learn library and split it into a training set and a testing setl\n",
    "# ~ Train a linear SVM classifier on the training set and predict the labels for the testing setl\n",
    "# ~ Compute the accuracy of the model on the testing setl\n",
    "# ~ Plot the decision boundaries of the trained model using two of the featuresl\n",
    "# ~ Try different values of the regularisation parameter C and see how it affects the performance of\n",
    "# the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff284e5a-d4ef-4c01-9662-91edf33072de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13d70989-e8e9-4650-b045-34016058cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8cf6578-be9d-4fd4-84e9-6019d968e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "935cbe68-186b-4b39-b661-0898b55e47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f01250d0-5c77-437e-910e-73520ef6ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c2140b-3083-4a4f-842b-64ae8336a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert independent and dependent\n",
    "x = df.iloc[:,:-1]\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cca5855-2582-44ee-9f31-5eff84756cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b76d689d-c7a4-4e5a-a971-1e6089e44f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8b0e9c3-615a-4de7-bfb2-ca197f311ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = \"linear\")\n",
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3787bd0-8465-4c70-a493-ab61ead6b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9e24293-5e4f-4b34-95ba-82fa198bfda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646017699115044\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98e455-42dc-4cef-8d43-fb75709e7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
